# üîß Propuesta de Mejoras al Sistema de Generaci√≥n de Horarios

## üìã Problemas Identificados

### 1. **Reparto Inicial Demasiado Pobre**
El sistema realiza m√∫ltiples intentos (10-60) de reparto inicial, pero la calidad sigue siendo insuficiente.

**Causas ra√≠z:**
- ‚ùå Scoring demasiado conservador que penaliza en lugar de incentivar
- ‚ùå Constraints 7/14 demasiado estrictos en fase inicial (solo se relajan en nivel 2)
- ‚ùå L√≥gica de "reserve capacity" que bloquea asignaciones prematuramente
- ‚ùå Gap constraints muy restrictivos para workers con d√©ficit
- ‚ùå No hay suficiente "agresividad" para llenar el schedule en el primer intento

### 2. **Iteraciones Demasiado Agresivas**
El optimizador hace 50 iteraciones con redistribuciones masivas (155+ cambios por iteraci√≥n).

**Causas ra√≠z:**
- ‚ùå No hay early stopping inteligente (solo para = 0 violations)
- ‚ùå Redistribuciones muy agresivas (violations √ó 10-15)
- ‚ùå Multi-shift strategy intenta hasta 5 shifts por worker
- ‚ùå No eval√∫a si las iteraciones est√°n mejorando realmente
- ‚ùå Sistema trabaja sobre un schedule inicial pobre

---

## üéØ Estrategia de Soluci√≥n

### **Principio fundamental:** 
**"Un buen reparto inicial requiere menos optimizaci√≥n agresiva"**

### **Enfoque en 2 fases:**

#### **Fase 1: MEJORAR EL REPARTO INICIAL** (Mayor impacto)
- ‚úÖ Scoring m√°s agresivo para llenar el schedule
- ‚úÖ Relaxaci√≥n progresiva de constraints dentro de cada intento
- ‚úÖ M√∫ltiples pasadas por intento con scoring diferente
- ‚úÖ Priorizar llenar schedule antes que perfecta distribuci√≥n

#### **Fase 2: OPTIMIZAR LAS ITERACIONES** (Menor impacto, pero necesario)
- ‚úÖ Early stopping inteligente (mejora < threshold)
- ‚úÖ Redistribuciones escaladas progresivamente
- ‚úÖ Menos iteraciones pero m√°s efectivas
- ‚úÖ Mejor detecci√≥n de estancamiento

---

## üî® Cambios Propuestos

### **A. MEJORAR REPARTO INICIAL**

#### **A1. Sistema de M√∫ltiples Pasadas por Intento**

Cada intento har√° **3-4 pasadas** con diferentes configuraciones:

```python
# Pasada 1: AGGRESSIVE FILL (relaxation=0-1)
# - Prioridad: Llenar schedule
# - Bonus muy alto para deficit
# - Penalties reducidas
# - Pattern 7/14 relajado

# Pasada 2: BALANCE FILL (relaxation=1)
# - Prioridad: Balancear carga
# - Ajustar desequilibrios
# - Pattern 7/14 moderado

# Pasada 3: FINE TUNING (relaxation=0)
# - Prioridad: Respetar targets
# - Pattern 7/14 estricto
# - Llenar huecos finales
```

**Configuraci√≥n por pasada:**

| Pasada | Relaxation | Bonus Deficit | Penalty Excess | Pattern 7/14 | Gap Min |
|--------|------------|---------------|----------------|--------------|---------|
| 1      | 0-1        | 5000          | 1000           | Relajado     | normal  |
| 2      | 1          | 3000          | 2000           | Moderado     | normal  |
| 3      | 0          | 2000          | 5000           | Estricto     | normal  |

#### **A2. Modificar Scoring en `schedule_builder.py`**

**Cambios en `_calculate_target_shift_score()`:**

```python
# ACTUAL: Bonus 3000 por shift de d√©ficit
# PROPUESTA: Bonus 5000 en primera pasada, luego 3000

if shift_difference > 0:
    # Bonus escalonado seg√∫n pasada
    if self.current_fill_pass == 1:
        score += shift_difference * 5000  # MUY AGRESIVO
    else:
        score += shift_difference * 3000  # MODERADO
```

**Cambios en `_calculate_overall_target_score()`:**

```python
# ACTUAL: Bloquea si excede +10% en relaxation < 2
# PROPUESTA: Permitir hasta +15% en primera pasada

if self.current_fill_pass == 1:
    # Primera pasada: m√°s permisivo
    max_allowed = int(overall_target_shifts * 1.15)  # +15%
else:
    # Pasadas posteriores: estricto
    max_allowed = int(overall_target_shifts * 1.10)  # +10%
```

**Cambios en `_check_gap_constraints()`:**

```python
# ACTUAL: Pattern 7/14 solo se relaja en relaxation=2 con deficit>=5
# PROPUESTA: Relajar en primera pasada con deficit>=2

if (days_between == 7 or days_between == 14):
    # Primera pasada: m√°s permisivo
    if self.current_fill_pass == 1 and target_deficit >= 2:
        logging.debug("Pattern 7/14 relajado en pasada inicial")
        continue
    # Pasadas posteriores: estricto
    elif relaxation_level >= 2 and target_deficit >= 5:
        continue
    else:
        return False
```

#### **A3. Implementar Sistema de Pasadas**

**Nuevo m√©todo en `schedule_builder.py`:**

```python
def _fill_schedule_with_multiple_passes(self):
    """
    Llena el schedule en m√∫ltiples pasadas con diferentes prioridades.
    
    Pasada 1: AGGRESSIVE FILL - Llenar m√°ximo posible
    Pasada 2: BALANCE FILL - Balancear distribuci√≥n
    Pasada 3: FINE TUNING - Ajustes finales
    
    Returns:
        bool: True if schedule successfully filled
    """
    passes_config = [
        {
            'pass_num': 1,
            'name': 'AGGRESSIVE FILL',
            'relaxation_range': (0, 1),
            'target_fill_percentage': 95,  # Intentar llenar 95%
            'scoring_multiplier': 1.5      # Bonuses x1.5
        },
        {
            'pass_num': 2,
            'name': 'BALANCE FILL',
            'relaxation_range': (1, 1),
            'target_fill_percentage': 98,  # Llenar 98%
            'scoring_multiplier': 1.0      # Bonuses normales
        },
        {
            'pass_num': 3,
            'name': 'FINE TUNING',
            'relaxation_range': (0, 2),
            'target_fill_percentage': 100, # Llenar 100%
            'scoring_multiplier': 0.8      # Bonuses reducidos
        }
    ]
    
    for pass_config in passes_config:
        self.current_fill_pass = pass_config['pass_num']
        self.scoring_multiplier = pass_config['scoring_multiplier']
        
        logging.info(f"\n{'‚îÄ' * 60}")
        logging.info(f"üéØ Pass {pass_config['pass_num']}: {pass_config['name']}")
        logging.info(f"{'‚îÄ' * 60}")
        
        # Calcular huecos restantes
        empty_count = self._count_empty_shifts()
        total_shifts = self._count_total_shifts()
        fill_percentage = ((total_shifts - empty_count) / total_shifts * 100)
        
        logging.info(f"Current fill: {fill_percentage:.1f}%")
        logging.info(f"Target fill: {pass_config['target_fill_percentage']}%")
        
        # Intentar llenar con relaxation progresiva
        for relax_level in range(*pass_config['relaxation_range']):
            self._fill_empty_shifts_with_relaxation(relax_level)
            
        # Evaluar progreso
        new_empty_count = self._count_empty_shifts()
        filled_in_pass = empty_count - new_empty_count
        logging.info(f"‚úì Filled {filled_in_pass} shifts in this pass")
        
        # Si ya llegamos al target, siguiente pasada
        new_fill_pct = ((total_shifts - new_empty_count) / total_shifts * 100)
        if new_fill_pct >= pass_config['target_fill_percentage']:
            logging.info(f"‚úÖ Target achieved: {new_fill_pct:.1f}%")
        else:
            logging.warning(f"‚ö†Ô∏è Below target: {new_fill_pct:.1f}%")
    
    # Resetear estado
    self.current_fill_pass = 0
    self.scoring_multiplier = 1.0
    
    return True
```

---

### **B. OPTIMIZAR ITERACIONES**

#### **B1. Early Stopping Inteligente**

**Modificar `_should_stop_optimization()` en `iterative_optimizer.py`:**

```python
def _should_stop_optimization(self, iteration: int, current_violations: int) -> bool:
    """
    Stopping criteria inteligente basado en mejora real.
    
    CRITERIA:
    1. Perfect schedule (violations = 0)
    2. Stagnation > threshold con violations bajas (< 5)
    3. Mejora promedio < 0.3 violations/iteration en √∫ltimas 10 iterations
    4. Violations aumentan consistentemente (3+ iterations)
    """
    # 1. Perfect schedule
    if current_violations == 0:
        logging.info("‚úÖ Perfect schedule - stopping")
        return True
    
    # 2. Low violations + stagnation
    if current_violations <= 5 and self.stagnation_counter >= 5:
        logging.info(f"‚úÖ Acceptable violations ({current_violations}) + stagnation - stopping")
        return True
    
    # 3. Low improvement rate
    if len(self.optimization_history) >= 10:
        recent_10 = self.optimization_history[-10:]
        improvement = recent_10[0]['total_violations'] - recent_10[-1]['total_violations']
        avg_improvement = improvement / 10
        
        if avg_improvement < 0.3:  # Menos de 0.3 violations por iteration
            logging.info(f"‚èπÔ∏è Low improvement rate ({avg_improvement:.2f}/iter) - stopping")
            return True
    
    # 4. Consistent worsening
    if len(self.optimization_history) >= 3:
        recent_3 = self.optimization_history[-3:]
        if all(recent_3[i]['total_violations'] >= recent_3[i-1]['total_violations'] 
               for i in range(1, 3)):
            logging.warning("‚èπÔ∏è Violations increasing - stopping")
            return True
    
    return False
```

#### **B2. Redistribuciones Escalonadas**

**Modificar `_apply_forced_redistribution()` en `iterative_optimizer.py`:**

```python
def _calculate_redistribution_limit(self, violations: int, iteration: int):
    """
    Calcula l√≠mite de redistribuciones de forma escalada.
    
    ESTRATEGIA:
    - Iterations 1-10: Moderado (violations √ó 3-5)
    - Iterations 11-25: Agresivo (violations √ó 6-8)
    - Iterations 26-50: Muy agresivo (violations √ó 10-15)
    """
    if iteration <= 10:
        # Fase inicial: exploraci√≥n moderada
        base = violations * 3
        max_limit = violations * 5
    elif iteration <= 25:
        # Fase media: incrementar agresividad
        base = violations * 6
        max_limit = violations * 8
    else:
        # Fase final: m√°xima agresividad
        base = violations * 10
        max_limit = violations * 15
    
    # Ajustar seg√∫n gravedad
    if violations > 20:
        return max_limit
    else:
        return base
```

#### **B3. Reducir N√∫mero M√°ximo de Iteraciones**

```python
# ACTUAL: max_iterations = 50
# PROPUESTA: max_iterations = 30

# Con mejor reparto inicial, 30 iteraciones deber√≠an ser suficientes
# Si el reparto inicial es bueno (< 15 violations), incluso menos
```

---

## üìä Impacto Esperado

### **Mejoras en Reparto Inicial:**

| M√©trica | Actual | Objetivo | Mejora |
|---------|--------|----------|--------|
| Shifts vac√≠os despu√©s de fase inicial | 5-15% | < 2% | 70%+ |
| Violaciones despu√©s de fase inicial | 30-35 | 10-15 | 55%+ |
| Workers con d√©ficit > 10 shifts | 8-12 | 0-3 | 75%+ |
| Tiempo fase inicial | 5-8 min | 8-12 min | +50% tiempo OK |

### **Mejoras en Optimizaci√≥n:**

| M√©trica | Actual | Objetivo | Mejora |
|---------|--------|----------|--------|
| Iteraciones necesarias | 50 | 15-25 | 50%+ |
| Redistributions por iteration | 140-180 | 50-100 | 40%+ |
| Tiempo optimizaci√≥n | 90 seg | 40-60 seg | 35%+ |
| Violaciones finales | 28-31 | 0-5 | 85%+ |

### **Beneficios Generales:**

‚úÖ **Mejor calidad:** Reparto inicial m√°s equilibrado y completo
‚úÖ **Menos trabajo para optimizador:** Schedule inicial cercano al √≥ptimo
‚úÖ **Convergencia m√°s r√°pida:** Menos iteraciones necesarias
‚úÖ **Mejor estabilidad:** Menos cambios masivos en optimization
‚úÖ **Tiempo similar o mejor:** M√°s tiempo inicial, menos tiempo optimization

---

## üöÄ Plan de Implementaci√≥n

### **Prioridad 1: Mejorar Reparto Inicial (CR√çTICO)**

1. ‚úÖ Implementar `current_fill_pass` tracking en `schedule_builder.py`
2. ‚úÖ Modificar scoring para usar `current_fill_pass`
3. ‚úÖ Crear `_fill_schedule_with_multiple_passes()`
4. ‚úÖ Integrar en `_try_multiple_initial_distributions()`
5. ‚úÖ Probar con dataset actual

### **Prioridad 2: Optimizar Iteraciones (IMPORTANTE)**

1. ‚úÖ Implementar early stopping inteligente
2. ‚úÖ Implementar redistribuciones escalonadas
3. ‚úÖ Reducir max_iterations de 50 a 30
4. ‚úÖ Probar con schedule mejorado de Prioridad 1

### **Prioridad 3: Fine Tuning (OPCIONAL)**

1. ‚úÖ Ajustar thresholds basado en resultados
2. ‚úÖ Optimizar n√∫mero de intentos iniciales
3. ‚úÖ Revisar scoring multipliers

---

## ‚ùì Decisiones Pendientes

1. **¬øCu√°ntas pasadas por intento inicial?**
   - Opci√≥n A: 3 pasadas (r√°pido, menos exhaustivo)
   - Opci√≥n B: 4 pasadas (m√°s lento, m√°s exhaustivo)
   - **Recomendaci√≥n:** Empezar con 3, evaluar resultados

2. **¬øBonuses en primera pasada?**
   - Opci√≥n A: 5000 (muy agresivo)
   - Opci√≥n B: 4000 (moderadamente agresivo)
   - **Recomendaci√≥n:** 5000, el objetivo es llenar

3. **¬øMax iterations para optimizaci√≥n?**
   - Opci√≥n A: 20 (conservador)
   - Opci√≥n B: 30 (balanceado)
   - **Recomendaci√≥n:** 30, permite convergencia completa

4. **¬øMantener m√∫ltiples intentos iniciales?**
   - Opci√≥n A: Mantener 10-60 intentos
   - Opci√≥n B: Reducir a 5-30 intentos (con pasadas m√∫ltiples)
   - **Recomendaci√≥n:** Reducir a 5-20, cada intento es m√°s efectivo

---

## üìù Notas Finales

- **Testing cr√≠tico:** Cada cambio debe probarse con dataset completo
- **Rollback plan:** Mantener versi√≥n actual como backup
- **Logging exhaustivo:** Para diagnosticar problemas
- **M√©tricas claras:** Definir KPIs de √©xito antes de implementar

**¬øProceder con implementaci√≥n?**
